import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
from datetime import datetime
import os

def scrape_accessible_sites():
    """
    Scraping de sites plus accessibles que Indeed
    """
    print("üîç D√âMARRAGE SCRAPING SITES ACCESSIBLES...")
    print("=" * 60)
    
    all_offers = []
    
    # 1. LinkedIn (version simplifi√©e)
    print("\n1. üíº TENTATIVE LINKEDIN...")
    linkedin_offers = scrape_linkedin_simple()
    all_offers.extend(linkedin_offers)
    print(f"‚úÖ LinkedIn: {len(linkedin_offers)} offres")
    
    # 2. Glassdoor (version simplifi√©e)
    print("\n2. üè¢ TENTATIVE GLASSDOOR...")
    glassdoor_offers = scrape_glassdoor_simple()
    all_offers.extend(glassdoor_offers)
    print(f"‚úÖ Glassdoor: {len(glassdoor_offers)} offres")
    
    # 3. ChooseYourBoss (startups fran√ßaises)
    print("\n3. üöÄ TENTATIVE CHOOSEYOURBOSS...")
    cyb_offers = scrape_chooseyourboss()
    all_offers.extend(cyb_offers)
    print(f"‚úÖ ChooseYourBoss: {len(cyb_offers)} offres")
    
    return all_offers

def scrape_linkedin_simple():
    """Scraping LinkedIn simplifi√©"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept-Language': 'fr-FR,fr;q=0.9,en;q=0.8'
    }
    
    offers = []
    
    # URLs de recherche LinkedIn
    linkedin_urls = [
        "https://www.linkedin.com/jobs/search/?keywords=stage%20informatique&location=France",
        "https://www.linkedin.com/jobs/search/?keywords=alternance%20informatique&location=France"
    ]
    
    for url in linkedin_urls:
        try:
            print(f"   üîç Recherche: {url.split('=')[1].split('&')[0].replace('%20', ' ')}")
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # S√©lecteurs LinkedIn basiques
                job_elements = soup.find_all('div', class_=['base-search-card__info', 'job-search-card'])
                
                for job_elem in job_elements[:8]:  # Limiter √† 8 offres
                    offer = parse_linkedin_element(job_elem, url)
                    if offer:
                        offers.append(offer)
                
            time.sleep(3)
            
        except Exception as e:
            print(f"   ‚ùå Erreur LinkedIn: {e}")
    
    return offers

def parse_linkedin_element(element, url):
    """Parser un √©l√©ment LinkedIn"""
    try:
        # Titre
        title_elem = element.find(['h3', 'a'], class_=['base-search-card__title', 'job-title'])
        title = title_elem.get_text(strip=True) if title_elem else "Stage/Alternance Informatique"
        
        # Entreprise
        company_elem = element.find(['h4', 'a'], class_=['base-search-card__subtitle', 'company-name'])
        company = company_elem.get_text(strip=True) if company_elem else "Entreprise IT"
        
        # Localisation
        location_elem = element.find(['span', 'div'], class_=['job-search-card__location', 'location'])
        location = location_elem.get_text(strip=True) if location_elem else "France"
        
        contract_type = "Stage" if "stage" in url else "Alternance"
        
        return {
            'Intitul√© du poste': title,
            'Nom de l entreprise': company,
            'Ville ou r√©gion': location,
            'Date de publication': datetime.now().strftime("%d/%m/%Y"),
            'Type de contrat': contract_type,
            'Nombre d ann√©es d exp√©rience demand√©es': '0',
            'Niveau de seniorit√©': '√âtudiant',
            'Description du poste': f"Offre LinkedIn - {title} chez {company}",
            'Source': 'LinkedIn',
            'T√©l√©travail': 'Non sp√©cifi√©',
            'Comp√©tences mentionn√©es': extract_skills_from_title(title),
            'Fourchette salariale': 'Non sp√©cifi√©',
            'URL': url
        }
    except Exception as e:
        print(f"   ‚ö† Erreur parsing LinkedIn: {e}")
        return None

def scrape_glassdoor_simple():
    """Scraping Glassdoor simplifi√©"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    offers = []
    
    # URLs Glassdoor
    glassdoor_urls = [
        "https://www.glassdoor.fr/Emploi/stage-informatique-emplois-SRCH_KO0,18.htm",
        "https://www.glassdoor.fr/Emploi/alternance-informatique-emplois-SRCH_KO0,20.htm"
    ]
    
    for url in glassdoor_urls:
        try:
            search_type = "Stage" if "stage" in url else "Alternance"
            print(f"   üîç Recherche: {search_type}")
            
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # S√©lecteurs Glassdoor
                job_cards = soup.find_all('li', class_=['react-job-listing', 'jobListing'])
                
                for card in job_cards[:6]:  # Limiter √† 6 offres
                    offer = parse_glassdoor_card(card, search_type)
                    if offer:
                        offers.append(offer)
                
            time.sleep(4)
            
        except Exception as e:
            print(f"   ‚ùå Erreur Glassdoor: {e}")
    
    return offers

def parse_glassdoor_card(card, contract_type):
    """Parser une carte Glassdoor"""
    try:
        # Titre
        title_elem = card.find(['a', 'h3'], class_=['jobLink', 'job-title'])
        title = title_elem.get_text(strip=True) if title_elem else f"{contract_type} Informatique"
        
        # Entreprise
        company_elem = card.find(['span', 'div'], class_=['employer-name', 'company'])
        company = company_elem.get_text(strip=True) if company_elem else "Entreprise Tech"
        
        # Localisation
        location_elem = card.find(['span', 'div'], class_=['location', 'loc'])
        location = location_elem.get_text(strip=True) if location_elem else "France"
        
        return {
            'Intitul√© du poste': title,
            'Nom de l entreprise': company,
            'Ville ou r√©gion': location,
            'Date de publication': datetime.now().strftime("%d/%m/%Y"),
            'Type de contrat': contract_type,
            'Nombre d ann√©es d exp√©rience demand√©es': '0',
            'Niveau de seniorit√©': 'Junior',
            'Description du poste': f"Offre Glassdoor - {title} chez {company}",
            'Source': 'Glassdoor',
            'T√©l√©travail': 'Non sp√©cifi√©',
            'Comp√©tences mentionn√©es': extract_skills_from_title(title),
            'Fourchette salariale': 'Non sp√©cifi√©',
            'URL': "https://www.glassdoor.fr"
        }
    except Exception as e:
        print(f"   ‚ö† Erreur parsing Glassdoor: {e}")
        return None

def scrape_chooseyourboss():
    """Scraping ChooseYourBoss - startups fran√ßaises"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept-Language': 'fr-FR,fr;q=0.9,en;q=0.8'
    }
    
    offers = []
    
    # URLs ChooseYourBoss
    cyb_urls = [
        "https://www.chooseyourboss.com/offres/stage?q=informatique",
        "https://www.chooseyourboss.com/offres/stage?q=d%C3%A9veloppement",
        "https://www.chooseyourboss.com/offres/alternance?q=informatique",
        "https://www.chooseyourboss.com/offres/alternance?q=d%C3%A9veloppement"
    ]
    
    for url in cyb_urls:
        try:
            contract_type = "Stage" if "stage" in url else "Alternance"
            print(f"   üîç Recherche: {contract_type}")
            
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # S√©lecteurs ChooseYourBoss
                job_cards = soup.find_all('div', class_=['job-item', 'offer-card'])
                
                for card in job_cards[:10]:
                    offer = parse_chooseyourboss_card(card, contract_type)
                    if offer:
                        offers.append(offer)
                
            time.sleep(2)
            
        except Exception as e:
            print(f"   ‚ùå Erreur ChooseYourBoss: {e}")
    
    return offers

def parse_chooseyourboss_card(card, contract_type):
    """Parser une carte ChooseYourBoss"""
    try:
        # Titre
        title_elem = card.find(['h3', 'h2'], class_=['title', 'job-title'])
        title = title_elem.get_text(strip=True) if title_elem else f"{contract_type} Informatique"
        
        # Entreprise
        company_elem = card.find(['div', 'span'], class_=['company', 'employer'])
        company = company_elem.get_text(strip=True) if company_elem else "Startup Tech"
        
        # Localisation
        location_elem = card.find(['div', 'span'], class_=['location', 'city'])
        location = location_elem.get_text(strip=True) if location_elem else "France"
        
        # Salaire (parfois disponible sur ChooseYourBoss)
        salary_elem = card.find(['div', 'span'], class_=['salary', 'compensation'])
        salaire = salary_elem.get_text(strip=True) if salary_elem else "Non sp√©cifi√©"
        
        return {
            'Intitul√© du poste': title,
            'Nom de l entreprise': company,
            'Ville ou r√©gion': location,
            'Date de publication': datetime.now().strftime("%d/%m/%Y"),
            'Type de contrat': contract_type,
            'Nombre d ann√©es d exp√©rience demand√©es': '0',
            'Niveau de seniorit√©': '√âtudiant',
            'Description du poste': f"Offre ChooseYourBoss - {title} chez {company}",
            'Source': 'ChooseYourBoss',
            'T√©l√©travail': detect_teletravail_cyb(card),
            'Comp√©tences mentionn√©es': extract_skills_from_title(title),
            'Fourchette salariale': salaire,
            'URL': "https://www.chooseyourboss.com" + card.find('a')['href'] if card.find('a') else "Non disponible"
        }
    except Exception as e:
        print(f"   ‚ö† Erreur parsing ChooseYourBoss: {e}")
        return None

def detect_teletravail_cyb(card):
    """D√©tecter t√©l√©travail ChooseYourBoss"""
    card_text = str(card).lower()
    teletravail_keywords = ['remote', 't√©l√©travail', 'hybride', 'flexible']
    return 'Oui' if any(keyword in card_text for keyword in teletravail_keywords) else 'Non'

def extract_skills_from_title(title):
    """Extraire les comp√©tences depuis le titre"""
    title_lower = title.lower()
    skills = []
    
    competences_tech = [
        'python', 'java', 'javascript', 'react', 'angular', 'vue', 'node.js',
        'sql', 'mongodb', 'docker', 'kubernetes', 'aws', 'azure', 'gcp',
        'machine learning', 'data science', 'devops', 'cloud', 'php',
        'symfony', 'laravel', 'c#', '.net', 'html', 'css', 'typescript'
    ]
    
    for skill in competences_tech:
        if skill in title_lower:
            skills.append(skill)
    
    return ', '.join(skills) if skills else 'Non sp√©cifi√©'

def save_offers_csv(offers):
    """Sauvegarder les offres en CSV"""
    if not offers:
        print("‚ùå Aucune donn√©e √† sauvegarder")
        return None
    
    os.makedirs('data/offres', exist_ok=True)
    
    df = pd.DataFrame(offers)
    
    # R√©organiser les colonnes
    column_order = [
        'Intitul√© du poste',
        'Nom de l entreprise',
        'Ville ou r√©gion',
        'Date de publication',
        'Type de contrat',
        'Nombre d ann√©es d exp√©rience demand√©es',
        'Niveau de seniorit√©',
        'T√©l√©travail',
        'Fourchette salariale',
        'Comp√©tences mentionn√©es',
        'Source',
        'URL',
        'Description du poste'
    ]
    
    existing_columns = [col for col in column_order if col in df.columns]
    df = df[existing_columns]
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"data/offres/stages_alternance_{timestamp}.csv"
    df.to_csv(filename, index=False, encoding='utf-8')
    
    return filename

def create_demo_data():
    """Cr√©er des donn√©es de d√©monstration si le scraping √©choue"""
    print("üìù CR√âATION DE DONN√âES DE D√âMONSTRATION...")
    
    demo_offers = [
        {
            'Intitul√© du poste': 'Stage D√©veloppeur FullStack React/Node.js',
            'Nom de l entreprise': 'Startup Tech Paris',
            'Ville ou r√©gion': 'Paris',
            'Date de publication': '15/01/2024',
            'Type de contrat': 'Stage',
            'Nombre d ann√©es d exp√©rience demand√©es': '0',
            'Niveau de seniorit√©': '√âtudiant',
            'Description du poste': 'Stage en d√©veloppement FullStack avec React et Node.js. Participation √† des projets innovants.',
            'Source': 'Donn√©es D√©mo',
            'T√©l√©travail': 'Hybride',
            'Comp√©tences mentionn√©es': 'javascript, react, node.js, sql',
            'Fourchette salariale': 'Gratification l√©gale',
            'URL': 'https://example.com/offre1'
        },
        {
            'Intitul√© du poste': 'Alternance Data Analyst Python/SQL',
            'Nom de l entreprise': 'Data Company',
            'Ville ou r√©gion': 'Lyon',
            'Date de publication': '10/01/2024',
            'Type de contrat': 'Alternance',
            'Nombre d ann√©es d exp√©rience demand√©es': '0',
            'Niveau de seniorit√©': '√âtudiant',
            'Description du poste': 'Alternance en analyse de donn√©es avec Python, SQL et outils de visualisation.',
            'Source': 'Donn√©es D√©mo',
            'T√©l√©travail': 'Non',
            'Comp√©tences mentionn√©es': 'python, sql, data analysis, pandas',
            'Fourchette salariale': 'Salaire alternance',
            'URL': 'https://example.com/offre2'
        },
        {
            'Intitul√© du poste': 'Stage DevOps AWS/Docker',
            'Nom de l entreprise': 'Cloud Solutions',
            'Ville ou r√©gion': 'Toulouse',
            'Date de publication': '20/01/2024',
            'Type de contrat': 'Stage',
            'Nombre d ann√©es d exp√©rience demand√©es': '0',
            'Niveau de seniorit√©': '√âtudiant',
            'Description du poste': 'Stage en infrastructure cloud et automatisation avec AWS et Docker.',
            'Source': 'Donn√©es D√©mo',
            'T√©l√©travail': 'Oui',
            'Comp√©tences mentionn√©es': 'aws, docker, python, linux',
            'Fourchette salariale': 'Gratification l√©gale',
            'URL': 'https://example.com/offre3'
        },
        {
            'Intitul√© du poste': 'Alternance D√©veloppeur Mobile Flutter',
            'Nom de l entreprise': 'App Startup',
            'Ville ou r√©gion': 'Bordeaux',
            'Date de publication': '12/01/2024',
            'Type de contrat': 'Alternance',
            'Nombre d ann√©es d exp√©rience demand√©es': '0',
            'Niveau de seniorit√©': '√âtudiant',
            'Description du poste': 'Alternance en d√©veloppement mobile cross-platform avec Flutter.',
            'Source': 'Donn√©es D√©mo',
            'T√©l√©travail': 'Hybride',
            'Comp√©tences mentionn√©es': 'flutter, dart, mobile, android, ios',
            'Fourchette salariale': 'Salaire alternance',
            'URL': 'https://example.com/offre4'
        }
    ]
    
    return demo_offers

def main():
    """Programme principal"""
    print("üöÄ COLLECTE STAGES & ALTERNANCE 2024/2025")
    print("Sites accessibles: LinkedIn, Glassdoor, ChooseYourBoss")
    print("=" * 60)
    
    # Essayer le scraping r√©el
    offers = scrape_accessible_sites()
    
    # Si √©chec, utiliser les donn√©es de d√©monstration
    if not offers:
        print("\n‚ö† Le scraping a √©chou√©, utilisation de donn√©es de d√©monstration...")
        offers = create_demo_data()
    
    if offers:
        # Sauvegarde
        csv_file = save_offers_csv(offers)
        
        # Statistiques
        print(f"\nüìä R√âSULTATS:")
        print(f"üéØ Total offres collect√©es: {len(offers)}")
        
        df = pd.DataFrame(offers)
        
        print(f"üè¢ Entreprises uniques: {df['Nom de l entreprise'].nunique()}")
        print(f"üìç Villes repr√©sent√©es: {df['Ville ou r√©gion'].nunique()}")
        
        # R√©partition par source
        print(f"\nüîç R√âPARTITION PAR SOURCE:")
        source_stats = df['Source'].value_counts()
        for source, count in source_stats.items():
            print(f"   - {source}: {count} offres")
        
        # R√©partition par type
        print(f"\nüìÑ R√âPARTITION PAR TYPE DE CONTRAT:")
        contract_stats = df['Type de contrat'].value_counts()
        for contrat, count in contract_stats.items():
            print(f"   - {contrat}: {count} offres")
        
        print(f"\nüíæ FICHIER SAUVEGARD√â: {csv_file}")
        
        # Aper√ßu
        print(f"\nüëÄ APER√áU DES OFFRES:")
        preview_cols = ['Intitul√© du poste', 'Nom de l entreprise', 'Type de contrat', 'Source']
        print(df[preview_cols].to_string(index=False))
        
        return csv_file
    else:
        print("‚ùå Aucune offre collect√©e")
        return None

if _name_ == "_main_":
    result_file = main()
    
    if result_file:
        print(f"\n‚úÖ COLLECTE TERMIN√âE!")
        print(f"üì• Fichier CSV: {result_file}")
        df_result = pd.read_csv(result_file)
        print(f"üìä {len(df_result)} offres sauvegard√©es")
    else:
        print("\n‚ùå √âchec de la collecte")